{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度可分离卷积\n",
    "\n",
    "卷积神经网络进化版，功能一致，但是速度更快、表示效率更高\n",
    "\n",
    "卷积神经网络由卷积层和池化层组成，一般一个卷积层配一个池化层，多个卷积层配一个池化层也比较常见，局部相关，\n",
    "\n",
    "一般应用场景：\n",
    "- 2D卷积神经网络：图像识别\n",
    "- 1D卷积神经网络：智能翻译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 导入包，并打印版本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 1.14.0\n",
      "matplotlib: 3.1.0\n",
      "numpy: 1.16.4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "activations = tf.keras.activations\n",
    "mnist = tf.keras.datasets.mnist\n",
    "to_categorical = tf.keras.utils.to_categorical\n",
    "optimizers = tf.keras.optimizers\n",
    "losses = tf.keras.losses\n",
    "\n",
    "print('tensorflow: ' + str(tf.__version__))\n",
    "print('matplotlib: ' + str(matplotlib.__version__))\n",
    "print('numpy: ' + str(np.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准备样本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels_original), (test_images, test_labels_original) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((len(train_images), 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((len(test_images), 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels_original)\n",
    "test_labels = to_categorical(test_labels_original)\n",
    "\n",
    "val_samples = 30000\n",
    "\n",
    "data_train_images = train_images[val_samples:]\n",
    "data_train_labels = train_labels[val_samples:]\n",
    "\n",
    "val_images = train_images[:val_samples]\n",
    "val_labels = train_labels[:val_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0729 01:36:05.073590 140448259446592 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "separable_conv2d (SeparableC (None, 26, 26, 32)        73        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_1 (Separabl (None, 11, 11, 64)        2400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 105,587\n",
      "Trainable params: 105,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model_1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.SeparableConv2D(32, (3, 3), activation=activations.relu, input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.SeparableConv2D(64, (3, 3), activation=activations.relu))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation=activations.relu))\n",
    "    model.add(layers.Dense(10, activation=activations.softmax))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_model_2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(16, (5, 5), padding='same', input_shape=(28, 28, 1), activation=activations.relu))\n",
    "    model.add(layers.MaxPool2D((2, 1)))\n",
    "    model.add(layers.Conv2D(36, (5, 5), padding='same', activation=activations.relu))\n",
    "    model.add(layers.MaxPool2D((2, 1)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation=activations.relu))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation=activations.softmax))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model_1()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 编译模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss=losses.categorical_crossentropy,\n",
    "    metrics=['accuracy', 'mae', 'mse']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 30000 samples\n",
      "Epoch 1/10\n",
      "30000/30000 [==============================] - 17s 556us/sample - loss: 0.4364 - acc: 0.8726 - mean_absolute_error: 0.0423 - mean_squared_error: 0.0192 - val_loss: 0.1747 - val_acc: 0.9466 - val_mean_absolute_error: 0.0179 - val_mean_squared_error: 0.0081\n",
      "Epoch 2/10\n",
      "30000/30000 [==============================] - 17s 555us/sample - loss: 0.1347 - acc: 0.9574 - mean_absolute_error: 0.0136 - mean_squared_error: 0.0064 - val_loss: 0.1355 - val_acc: 0.9565 - val_mean_absolute_error: 0.0129 - val_mean_squared_error: 0.0066\n",
      "Epoch 3/10\n",
      "30000/30000 [==============================] - 17s 551us/sample - loss: 0.1056 - acc: 0.9662 - mean_absolute_error: 0.0107 - mean_squared_error: 0.0051 - val_loss: 0.0951 - val_acc: 0.9710 - val_mean_absolute_error: 0.0097 - val_mean_squared_error: 0.0045\n",
      "Epoch 4/10\n",
      "30000/30000 [==============================] - 17s 551us/sample - loss: 0.0864 - acc: 0.9717 - mean_absolute_error: 0.0089 - mean_squared_error: 0.0042 - val_loss: 0.0863 - val_acc: 0.9748 - val_mean_absolute_error: 0.0080 - val_mean_squared_error: 0.0039\n",
      "Epoch 5/10\n",
      "30000/30000 [==============================] - 17s 553us/sample - loss: 0.0728 - acc: 0.9772 - mean_absolute_error: 0.0074 - mean_squared_error: 0.0035 - val_loss: 0.0833 - val_acc: 0.9747 - val_mean_absolute_error: 0.0074 - val_mean_squared_error: 0.0039\n",
      "Epoch 6/10\n",
      "30000/30000 [==============================] - 17s 555us/sample - loss: 0.0619 - acc: 0.9810 - mean_absolute_error: 0.0063 - mean_squared_error: 0.0029 - val_loss: 0.0757 - val_acc: 0.9770 - val_mean_absolute_error: 0.0069 - val_mean_squared_error: 0.0036\n",
      "Epoch 7/10\n",
      "30000/30000 [==============================] - 16s 548us/sample - loss: 0.0555 - acc: 0.9828 - mean_absolute_error: 0.0057 - mean_squared_error: 0.0027 - val_loss: 0.0688 - val_acc: 0.9782 - val_mean_absolute_error: 0.0063 - val_mean_squared_error: 0.0033\n",
      "Epoch 8/10\n",
      "21312/30000 [====================>.........] - ETA: 3s - loss: 0.0441 - acc: 0.9859 - mean_absolute_error: 0.0047 - mean_squared_error: 0.0022"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    data_train_images,\n",
    "    data_train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_data=(val_images, val_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_samples = test_images[:100]\n",
    "y_samples = test_labels_original[:100]\n",
    "predications = model.predict(x_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 使用图形显示100个结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 25))\n",
    "for i in range(100):\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])    \n",
    "    plt.imshow(x_samples[i].reshape(28, 28), cmap=plt.cm.binary)\n",
    "    plt.grid(True)\n",
    "    if np.argmax(predications[i]) != test_labels_original[i]:       \n",
    "        plt.xlabel('predict:' + str(np.argmax(predications[i])) + ', actual:' + str(y_samples[i]), color='red')\n",
    "    else:\n",
    "        plt.xlabel('predict:' + str(np.argmax(predications[i])) + ', actual:' + str(y_samples[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
